{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba3f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2548d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b839834",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbed12ea",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da8558ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('./t5-base/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56cf3e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'Artificial Intelligence',\n",
       " '2': 'Cognitive Science and Neuroscience',\n",
       " '3': 'Image Processing',\n",
       " '4': 'Computer graphics',\n",
       " '5': 'Pattern Recognition or Machine Learning',\n",
       " '6': 'Image Representation',\n",
       " '7': 'Stereo Matching and 3D Reconstruction',\n",
       " '8': 'Motion Detection and Tracking',\n",
       " '9': 'edge detection',\n",
       " '10': 'segmentation',\n",
       " '11': 'contour and silhouette',\n",
       " '12': 'texture',\n",
       " '13': 'feature extraction',\n",
       " '14': 'local features or blob',\n",
       " '15': 'Camera calibration or resectioning',\n",
       " '16': 'Image Registration',\n",
       " '17': 'feature matching',\n",
       " '18': 'Background Subtraction',\n",
       " '19': 'background modeling and update',\n",
       " '20': 'color space',\n",
       " '21': 'Hue',\n",
       " '22': 'Saturation',\n",
       " '23': 'Color Constancy',\n",
       " '24': 'illumination',\n",
       " '25': 'Reflectance Model',\n",
       " '26': 'Shading Analysis',\n",
       " '27': 'Imaging Geometry and Physics',\n",
       " '28': 'Perspective projection',\n",
       " '29': 'radiance',\n",
       " '30': 'irradiance',\n",
       " '31': 'intensity',\n",
       " '32': 'diffuse surface',\n",
       " '33': 'Specular Surfaces',\n",
       " '34': 'interreflection',\n",
       " '35': 'Reflectance Map',\n",
       " '36': 'texture classification',\n",
       " '37': 'shape from texture',\n",
       " '38': 'graph rendering',\n",
       " '39': 'image compression',\n",
       " '40': 'statistical methods',\n",
       " '41': 'model based methods',\n",
       " '42': 'entropy',\n",
       " '43': 'energy',\n",
       " '44': 'contrast',\n",
       " '45': 'Gibbs sampling',\n",
       " '46': 'control points',\n",
       " '47': 'knot points',\n",
       " '48': 'basis function',\n",
       " '49': 'interpolation',\n",
       " '50': 'Regression',\n",
       " '51': 'Image thresholding',\n",
       " '52': 'connected component',\n",
       " '53': 'mathematical morphology',\n",
       " '54': 'structuring elements',\n",
       " '55': 'clustering',\n",
       " '56': 'region adjacency graphs',\n",
       " '57': 'sub-sampling',\n",
       " '58': 'Scale Space',\n",
       " '59': 'occlusion',\n",
       " '60': 'corner detection',\n",
       " '61': 'Second moment matrix or autocorrelation',\n",
       " '62': 'intra-class variability',\n",
       " '63': 'inter-class similarity',\n",
       " '64': 'Face detection',\n",
       " '65': 'ensemble classifier',\n",
       " '66': 'passive sensing',\n",
       " '67': 'dense depth',\n",
       " '68': 'Epipolar Geometry',\n",
       " '69': 'Rectification',\n",
       " '70': 'Gaussian Mixture Model',\n",
       " '71': 'Particle Filters',\n",
       " '72': 'color histogram',\n",
       " '73': 'Fourier transform',\n",
       " '74': 'Template Matching',\n",
       " '75': 'Convolutional Neural Network',\n",
       " '76': 'Backpropagation',\n",
       " '77': 'Pinhole Camera Model',\n",
       " '78': 'Bidirectional Reflectance Distribution Function',\n",
       " '79': 'Lambertian surfaces',\n",
       " '80': 'Structure from motion',\n",
       " '81': 'Optical flow',\n",
       " '82': 'Frenet frame and Frenet equations',\n",
       " '83': 'V1 visual cortex',\n",
       " '84': 'Projective Geometry',\n",
       " '85': 'projective plane',\n",
       " '86': 'Pose Estimation',\n",
       " '87': 'trifocal tensor',\n",
       " '88': 'Video and Image augmentation',\n",
       " '89': 'Euclidean reconstruction',\n",
       " '90': 'affine reconstruction',\n",
       " '91': 'radial distortion',\n",
       " '92': 'absolute conic',\n",
       " '93': 'vanishing points',\n",
       " '94': 'vanishing lines',\n",
       " '95': 'single view reconstruction',\n",
       " '96': 'fundamental matrix',\n",
       " '97': 'triangulation',\n",
       " '98': 'Sampson approximation',\n",
       " '99': 'bas relief ambiguity',\n",
       " '100': 'projective factorization',\n",
       " '101': 'Carlsson–Weinshall duality',\n",
       " '102': 'multi view geometry',\n",
       " '103': 'Object Localization',\n",
       " '104': 'Representation Learning',\n",
       " '105': 'Visual Odometry',\n",
       " '106': 'image classification',\n",
       " '107': 'image generation',\n",
       " '108': 'image to image translation',\n",
       " '109': 'image inpainting',\n",
       " '110': 'domain adaptation',\n",
       " '111': 'keypoint detection',\n",
       " '112': 'autonomous driving',\n",
       " '113': 'Simultaneous Localization and Mapping',\n",
       " '114': 'denoising',\n",
       " '115': 'video prediction',\n",
       " '116': 'video classification',\n",
       " '117': 'action or gesture recognition',\n",
       " '118': 'face recognition',\n",
       " '119': 'face alignment',\n",
       " '120': 'depth estimation',\n",
       " '121': 'few-shot learning',\n",
       " '122': 'zero-shot learning',\n",
       " '123': 'dimensionality reduction',\n",
       " '124': 'image retrieval',\n",
       " '125': 'quantization',\n",
       " '126': 'Scene understanding and scene parsing',\n",
       " '127': 'object recognition',\n",
       " '128': 'style transfer',\n",
       " '129': 'image captioning',\n",
       " '130': 'visual question answering',\n",
       " '131': 'emotion recognition',\n",
       " '132': 'contrastive learning',\n",
       " '133': 'image restoration',\n",
       " '134': 'optical character recognition',\n",
       " '135': 'saliency detection',\n",
       " '136': 'saliency prediction',\n",
       " '137': 'trajectory prediction',\n",
       " '138': 'image enhancement',\n",
       " '139': 'deblurring and dehazing',\n",
       " '140': 'crowd counting',\n",
       " '141': 'hyperspectral image',\n",
       " '142': 'eye tracking',\n",
       " '143': 'gaze estimation',\n",
       " '144': 'remote sensing',\n",
       " '145': 'human parsing',\n",
       " '146': 'image matting',\n",
       " '147': 'video summarization',\n",
       " '148': 'camera localization',\n",
       " '149': 'smoothing',\n",
       " '150': 'convolution',\n",
       " '151': 'gradient',\n",
       " '152': 'genetic algorithms',\n",
       " '153': 'semi-supervised learning',\n",
       " '154': 'graph theory',\n",
       " '155': 'matrix multiplication',\n",
       " '156': 'transfer learning',\n",
       " '157': 'gradient descent',\n",
       " '158': 'theory of computation',\n",
       " '159': 'search',\n",
       " '160': 'long short term memory networks',\n",
       " '161': 'reinforcement learning',\n",
       " '162': 'seq2seq',\n",
       " '163': 'feature learning',\n",
       " '164': 'conditional probability',\n",
       " '165': 'bayesian network',\n",
       " '166': 'decision trees',\n",
       " '167': 'optimization',\n",
       " '168': 'beam search',\n",
       " '169': 'classification',\n",
       " '170': 'knowledge graph',\n",
       " '171': 'recurrent neural networks',\n",
       " '172': 'imagenet',\n",
       " '173': 'deep Q-network',\n",
       " '174': 'attention models',\n",
       " '175': 'logistic regression',\n",
       " '176': 'data structures and algorithms',\n",
       " '177': 'information retrieval',\n",
       " '178': 'k means',\n",
       " '179': 'bio text mining',\n",
       " '180': 'preprocessing',\n",
       " '181': 'neural networks',\n",
       " '182': 'gated recurrent units',\n",
       " '183': 'relation extraction',\n",
       " '184': 'vector representations',\n",
       " '185': 'linear algebra',\n",
       " '186': 'cross entropy',\n",
       " '187': 'named entity recognition',\n",
       " '188': 'linear regression',\n",
       " '189': 'support vector machines',\n",
       " '190': 'singular value decomposition',\n",
       " '191': 'Unsupervised learning',\n",
       " '192': 'Sampling',\n",
       " '193': 'Naive Bayes',\n",
       " '194': 'Hidden Markov Models',\n",
       " '195': 'edit distance',\n",
       " '196': 'question answering',\n",
       " '197': 'information theory',\n",
       " '198': 'multi-task learning',\n",
       " '199': 'robotics',\n",
       " '200': 'perceptron',\n",
       " '201': 'object detection'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取字典\n",
    "CV_topic_dic = {}\n",
    "with open(\"./LectureBank/CV/CV.topics.tsv\",'r',encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        CV_topic_dic[line[0]] = line[1]\n",
    "CV_topic_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28175fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'conservation',\n",
       " '2': 'central dogma',\n",
       " '3': 'transcription',\n",
       " '4': 'translation',\n",
       " '5': 'DNA',\n",
       " '6': 'RNA',\n",
       " '7': 'protein',\n",
       " '8': 'single nucleotide polymorphism',\n",
       " '9': 'quantitative trait loci',\n",
       " '10': 'isoform',\n",
       " '11': 'CpG island',\n",
       " '12': 'transcription factor',\n",
       " '13': 'sequence alignment',\n",
       " '14': 'genome assembly',\n",
       " '15': 'motif discovery',\n",
       " '16': 'gene finding',\n",
       " '17': 'molecular evolution',\n",
       " '18': 'genome-wide association studies',\n",
       " '19': 'protein secondary structure',\n",
       " '20': 'protein tertriary structure',\n",
       " '21': 'RNA secondary structure',\n",
       " '22': 'differential expression',\n",
       " '23': 'binding site',\n",
       " '24': 'regulatory network',\n",
       " '25': 'protein-protein interaction',\n",
       " '26': 'microarray',\n",
       " '27': 'RNA-seq',\n",
       " '28': 'ChIP-seq',\n",
       " '29': 'yeast 2-hybrid',\n",
       " '30': 'shotgun sequencing',\n",
       " '31': 'position weight matrix',\n",
       " '32': 'BLAST',\n",
       " '33': 'de Bruijin graph',\n",
       " '34': 'irreproducible discovery rate',\n",
       " '35': 'DESeq',\n",
       " '36': 'phylogenetic tree',\n",
       " '37': 'bayesian inference',\n",
       " '38': 'multivariate linear model',\n",
       " '39': 'additive model',\n",
       " '40': 'chi-square test',\n",
       " '41': 'linkage disequilibrium',\n",
       " '42': 'hardy-weinberg equilibrium',\n",
       " '43': 'hypothesis testing',\n",
       " '44': 'false discovery rate',\n",
       " '45': 'binding energy',\n",
       " '46': 'energy minimization',\n",
       " '47': 'homology model',\n",
       " '48': 'mutual information',\n",
       " '49': 'markov clustering',\n",
       " '50': 'genetic algorithms',\n",
       " '51': 'semi-supervised learning',\n",
       " '52': 'graph theory',\n",
       " '53': 'matrix multiplication',\n",
       " '54': 'transfer learning',\n",
       " '55': 'gradient descent',\n",
       " '56': 'search',\n",
       " '57': 'long short term memory networks',\n",
       " '58': 'feature learning',\n",
       " '59': 'conditional probability',\n",
       " '60': 'bayesian network',\n",
       " '61': 'decision trees',\n",
       " '62': 'optimization',\n",
       " '63': 'beam search',\n",
       " '64': 'classification',\n",
       " '65': 'knowledge graph',\n",
       " '66': 'recurrent neural networks',\n",
       " '67': 'imagenet',\n",
       " '68': 'deep Q-network',\n",
       " '69': 'attention models',\n",
       " '70': 'logistic regression',\n",
       " '71': 'data structures and algorithms',\n",
       " '72': 'k means',\n",
       " '73': 'bio text mining',\n",
       " '74': 'preprocessing',\n",
       " '75': 'neural networks',\n",
       " '76': 'gated recurrent units',\n",
       " '77': 'relation extraction',\n",
       " '78': 'vector representations',\n",
       " '79': 'linear algebra',\n",
       " '80': 'cross entropy',\n",
       " '81': 'linear regression',\n",
       " '82': 'support vector machines',\n",
       " '83': 'singular value decomposition',\n",
       " '84': 'Unsupervised learning',\n",
       " '85': 'Sampling',\n",
       " '86': 'Naive Bayes',\n",
       " '87': 'Hidden Markov Models',\n",
       " '88': 'edit distance',\n",
       " '89': 'information theory',\n",
       " '90': 'multi-task learning',\n",
       " '91': 'robotics',\n",
       " '92': 'perceptron',\n",
       " '93': 'Principal Component Analysis',\n",
       " '94': 'clustering',\n",
       " '95': 'convolutional neural network',\n",
       " '96': 'dynamic programming',\n",
       " '97': 'maximum likelihood estimation',\n",
       " '98': 'expectation maximization algorithm',\n",
       " '99': 'gibbs sampling',\n",
       " '100': 'markov chain monte carlo'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取字典\n",
    "BIO_topic_dic = {}\n",
    "with open(\"./LectureBank/BIO/BIO.topics.tsv\",'r',encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        BIO_topic_dic[line[0]] = line[1]\n",
    "BIO_topic_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b357422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./wiki80/wiki80_train.txt\",'r',encoding='utf-8') as f:\n",
    "#         lines = f.readlines()\n",
    "#         for line in lines:\n",
    "#             data = json.loads(line)\n",
    "#             h_entity_replace = randomLetter()\n",
    "#             t_entity_replace = randomLetter()\n",
    "#             plus_text = data['token'][0:data['h']['pos'][0]] + [h_entity_replace] +  data['token'][data['h']['pos'][1]:data['t']['pos'][0]] + [t_entity_replace] + data['token'][data['h']['pos'][1]:] \n",
    "#             plus_text = \" \".join(plus_text)\n",
    "#             plus_text = \"extract relation: \" + plus_text.lower() + \" </s>\"\n",
    "#             rel_text = h_entity_replace.lower() + \" - \" +  data['relation'].lower() + ' - ' + t_entity_replace.lower() + \" </s>\"\n",
    "#             print(plus_text)\n",
    "#             print(rel_text)\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffb0091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filepath,tokenizer):\n",
    "    origin_texts = []\n",
    "    rel_texts = []\n",
    "    max_input_len = 0\n",
    "    max_output_len = 0\n",
    "    with open(filepath,'r',encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip().split(\",\")\n",
    "            lecture1 = CV_topic_dic[line[0]]\n",
    "            lecture2 = CV_topic_dic[line[1]]\n",
    "            text = \"judge prerequisite: \" + lecture1 + \" \" + lecture2 + \" </s>\"\n",
    "            if line[2] == \"0\":\n",
    "                rel_text = \"0\"\n",
    "            elif line[2] == \"1\":\n",
    "                rel_text = \"1\"\n",
    "            #rel_text = lecture1 + \" - \" +  rel + ' - ' + lecture2 + \" </s>\"\n",
    "            origin_texts.append(text)\n",
    "            rel_texts.append(rel_text)\n",
    "            tokenized_inp = tokenizer.encode_plus(text, return_tensors=\"pt\")\n",
    "            tokenized_output = tokenizer.encode_plus(rel_text,return_tensors=\"pt\")\n",
    "            input_ids  = tokenized_inp[\"input_ids\"]\n",
    "            output_ids  = tokenized_output[\"input_ids\"]\n",
    "            max_input_len = max(max_input_len, input_ids.shape[1])\n",
    "            max_output_len = max(max_output_len, output_ids.shape[1])\n",
    "            \n",
    "            # 数据增强\n",
    "            # 用两个随机字母替换两个实体\n",
    "#             h_entity_replace = randomLetter()\n",
    "#             t_entity_replace = randomLetter()\n",
    "#             first_entity_pos = []\n",
    "#             second_entity_pos = []\n",
    "#             if data['h']['pos'][0] < data['t']['pos'][0]:\n",
    "#                 first_entity_pos = data['h']['pos']\n",
    "#                 second_entity_pos = data['t']['pos']\n",
    "#             else:\n",
    "#                 first_entity_pos = data['t']['pos']\n",
    "#                 second_entity_pos = data['h']['pos']\n",
    "#             plus_text = data['token'][0:first_entity_pos[0]] + [h_entity_replace] +  data['token'][first_entity_pos[1]:second_entity_pos[0]] + [t_entity_replace] + data['token'][second_entity_pos[1]:] \n",
    "#             plus_text = \" \".join(plus_text)\n",
    "#             plus_text = \"extract relation: \" + plus_text.lower() + \" </s>\"\n",
    "#             rel_text = h_entity_replace.lower() + \" - \" +  data['relation'].lower() + ' - ' + t_entity_replace.lower() + \" </s>\"\n",
    "#             print(plus_text)\n",
    "#             print(rel_text)\n",
    "#             origin_texts.append(plus_text)\n",
    "#             rel_texts.append(rel_text)\n",
    "    print(max_input_len)\n",
    "    print(max_output_len)\n",
    "    return origin_texts,rel_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f01d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_val_data(filepath,tokenizer):\n",
    "    origin_texts = []\n",
    "    rel_texts = []\n",
    "    max_input_len = 0\n",
    "    max_output_len = 0\n",
    "    with open(filepath,'r',encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip().split(\",\")\n",
    "            lecture1 = BIO_topic_dic[line[0]]\n",
    "            lecture2 = BIO_topic_dic[line[1]]\n",
    "            text = \"judge prerequisite: \" + lecture1 + \" \" + lecture2 + \" </s>\"\n",
    "            if line[2] == \"0\":\n",
    "                rel_text = \"0\"\n",
    "            elif line[2] == \"1\":\n",
    "                rel_text = \"1\"\n",
    "            # rel_text = lecture1 + \" - \" +  rel + ' - ' + lecture2\n",
    "            origin_texts.append(text)\n",
    "            rel_texts.append(rel_text)\n",
    "    return origin_texts,rel_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "223159f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extract_Dataset(Dataset):\n",
    "    def __init__(self, filepaths, tokenizer,max_input_len,max_output_len):\n",
    "        self.origin_texts, self.rel_texts = [],[]\n",
    "        for filepath in filepaths:\n",
    "            o,r = extract_data(filepath,tokenizer)\n",
    "            self.origin_texts.extend(o)\n",
    "            self.rel_texts.extend(r)\n",
    "        self.max_input_len = max_input_len\n",
    "        self.max_output_len = max_output_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.origin_texts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        tokenized_input = tokenizer.encode_plus(self.origin_texts[index], max_length=self.max_input_len, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "        tokenized_output = tokenizer.encode_plus(self.rel_texts[index], max_length=self.max_output_len, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "        \n",
    "        input_ids  = tokenized_input[\"input_ids\"].squeeze()\n",
    "        attention_mask = tokenized_input[\"attention_mask\"].squeeze()\n",
    "\n",
    "        output_ids = tokenized_output[\"input_ids\"].squeeze()\n",
    "        decoder_attention_mask=  tokenized_output[\"attention_mask\"].squeeze()\n",
    "        \n",
    "        data = {\n",
    "            'input_ids':input_ids,\n",
    "            'attention_mask':attention_mask,\n",
    "            'output_ids':output_ids,\n",
    "            'decoder_attention_mask':decoder_attention_mask\n",
    "        }\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e14bdc",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f294718",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained('./t5-base/').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "359c3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in t5_model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in t5_model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d25e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):   # 训练模型\n",
    "    model.train()\n",
    "    with tqdm(total=len(train_loader)) as bar:\n",
    "        for idx,data in enumerate(train_loader):\n",
    "            input_ids, attention_mask, output_ids, decoder_attention_mask = data['input_ids'].to(device), data['attention_mask'].to(device), data['output_ids'].to(device), data['decoder_attention_mask'].to(device)\n",
    "            output = model(input_ids=input_ids, labels=output_ids,decoder_attention_mask=decoder_attention_mask,attention_mask=attention_mask)\n",
    "            loss = output[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            bar.set_postfix(loss=loss.item())\n",
    "            bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef3dfebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, tokenizer,device, filepaths):\n",
    "    origin_texts, rel_texts = [], []\n",
    "    for filepath in filepaths:\n",
    "        o,r= extract_val_data(filepath,tokenizer)\n",
    "        origin_texts.extend(o)\n",
    "        rel_texts.extend(r)\n",
    "    model.eval()\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    with tqdm(total=len(origin_texts)) as bar:\n",
    "        for idx, text in enumerate(origin_texts):\n",
    "            input_ids = tokenizer(text, return_tensors='pt').input_ids.to(DEVICE)\n",
    "            outputs = t5_model.generate(input_ids)\n",
    "            result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            rel_text = rel_texts[idx]\n",
    "#             print(rel_text)\n",
    "#             print(result)\n",
    "            if result == \"1\":\n",
    "#                 print(1)\n",
    "                if result == rel_text:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "            else:\n",
    "                if result != rel_text:\n",
    "                    FN += 1\n",
    "            bar.update(1)\n",
    "    print(TP)\n",
    "    print(FP)\n",
    "    print(FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    return precision,recall,F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37558edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyq/miniconda3/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:174: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "3\n",
      "22\n",
      "3\n",
      "20\n",
      "3\n",
      "22\n",
      "3\n",
      "21\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "filepaths = [\"./LectureBank/CV/train.0.csv\",\"./LectureBank/CV/train.1.csv\",\"./LectureBank/CV/train.2.csv\",\"./LectureBank/CV/train.3.csv\",\"./LectureBank/CV/train.4.csv\"]\n",
    "train_dataset = Extract_Dataset(filepaths=filepaths,tokenizer=tokenizer,max_input_len=40,max_output_len=40)\n",
    "train_loader = DataLoader(train_dataset,shuffle=True,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "705f04f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/232 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/zyq/miniconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2073: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 232/232 [00:35<00:00,  6.54it/s, loss=0.0181]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1d2c090050e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt5_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt5_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"./LectureBank/CV/val.0.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./LectureBank/CV/val.1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./LectureBank/CV/val.2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./LectureBank/CV/val.3.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./LectureBank/CV/val.4.csv\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EPOCH:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision：\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-e5f40a841a8e>\u001b[0m in \u001b[0;36mval\u001b[0;34m(model, tokenizer, device, filepath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0morigin_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_val_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mTP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mFP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d1cd0a4180d4>\u001b[0m in \u001b[0;36mextract_val_data\u001b[0;34m(filepath, tokenizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmax_input_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_output_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHES = 8\n",
    "with open(\"./log(lecturebank-nonlabel).txt\",'w',encoding='utf-8') as f:\n",
    "    for epoch in range(NUM_EPOCHES):\n",
    "        train(t5_model,DEVICE,train_loader,optimizer)\n",
    "        precision,recall,F1 = val(t5_model,tokenizer,DEVICE,[\"./LectureBank/CV/val.0.csv\",\"./LectureBank/CV/val.1.csv\",\"./LectureBank/CV/val.2.csv\",\"./LectureBank/CV/val.3.csv\",\"./LectureBank/CV/val.4.csv\"])\n",
    "        f.write(\"EPOCH:\" + str(epoch) + \"\\n\")\n",
    "        f.write(\"precision：\" + str(precision) + \"\\n\")\n",
    "        f.write(\"recall：\" + str(recall) + \"\\n\")\n",
    "        f.write(\"F1：\" + str(F1) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "070fa217",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'118'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b799f65910e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt5_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"./LectureBank/CV/val.0.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./LectureBank/CV/val.1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./LectureBank/CV/val.2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./LectureBank/CV/val.3.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./LectureBank/CV/val.4.csv\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EPOCH:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision：\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recall：\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F1：\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-5df3cc31d5a9>\u001b[0m in \u001b[0;36mval\u001b[0;34m(model, tokenizer, device, filepaths)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0morigin_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilepaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mextract_val_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0morigin_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mrel_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d1cd0a4180d4>\u001b[0m in \u001b[0;36mextract_val_data\u001b[0;34m(filepath, tokenizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mlecture1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBIO_topic_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mlecture2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBIO_topic_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"judge prerequisite: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlecture1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlecture2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" </s>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '118'"
     ]
    }
   ],
   "source": [
    "precision,recall,F1 = val(t5_model,tokenizer,DEVICE,[\"./LectureBank/CV/val.0.csv\",\"./LectureBank/CV/val.1.csv\",\"./LectureBank/CV/val.2.csv\",\"./LectureBank/CV/val.3.csv\",\"./LectureBank/CV/val.4.csv\"])\n",
    "f.write(\"EPOCH:\" + str(epoch) + \"\\n\")\n",
    "f.write(\"precision：\" + str(precision) + \"\\n\")\n",
    "f.write(\"recall：\" + str(recall) + \"\\n\")\n",
    "f.write(\"F1：\" + str(F1) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a21de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = tokenizer(t, return_tensors='pt').input_ids.to(DEVICE)\n",
    "# outputs = t5_model.generate(input_ids)\n",
    "# print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d900a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# result.split(\" - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d62bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(val(t5_model,tokenizer,DEVICE,\"./semeval/semeval_val.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86acf595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_rel,acc_entity,acc_all = val(t5_model,tokenizer,DEVICE,\"./LectureBank/val.0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e2d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488cd59b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
